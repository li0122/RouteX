"""
å®Œæ•´ä½¿ç”¨ç¯„ä¾‹ - RouteX æ—…éŠæ¨è–¦ç³»çµ± + LLMéæ¿¾
å±•ç¤ºå¾åˆå§‹åŒ–åˆ°ç²å¾—æœ€çµ‚æ¨è–¦çš„å®Œæ•´æµç¨‹
"""

import torch
import json
from route_aware_recommender import create_route_recommender, OSRMClient

try:
    from simple_llm_filter import SimpleLLMFilter
    LLM_FILTER_AVAILABLE = True
except ImportError:
    LLM_FILTER_AVAILABLE = False


def example_1_basic_usage():
    """ç¯„ä¾‹1: åŸºæœ¬ä½¿ç”¨ï¼ˆä¸ä½¿ç”¨LLMéæ¿¾ï¼‰"""
    
    print("=" * 60)
    print("ğŸ“š ç¯„ä¾‹1: åŸºæœ¬æ¨è–¦ç³»çµ±ä½¿ç”¨")
    print("=" * 60)
    
    # æ­¥é©Ÿ1: åˆå§‹åŒ–æ¨è–¦å™¨
    print("\nğŸ”§ æ­¥é©Ÿ1: åˆå§‹åŒ–æ¨è–¦å™¨")
    
    osrm_client = OSRMClient(server_url="http://router.project-osrm.org")
    
    recommender = create_route_recommender(
        poi_data_path='datasets/meta-California.json.gz',
        model_checkpoint='models/travel_dlrm.pth',
        device='cuda' if torch.cuda.is_available() else 'cpu',
        enable_spatial_index=True,
        enable_async=True
    )
    recommender.osrm_client = osrm_client
    recommender.enable_llm_filter = False
    
    print("âœ… æ¨è–¦å™¨åˆå§‹åŒ–å®Œæˆ")
    
    # æ­¥é©Ÿ2: è¨­å®šç”¨æˆ¶è³‡è¨Šå’Œç›®æ¨™ä½ç½®
    print("\nğŸ“ æ­¥é©Ÿ2: è¨­å®šæ¨è–¦åƒæ•¸")
    user_id = 1
    current_lat = 37.7749  # èˆŠé‡‘å±±
    current_lon = -122.4194
    destination_lat = 37.8199  # é‡‘é–€å¤§æ©‹
    destination_lon = -122.4783
    top_k = 5
    
    print(f"   ç”¨æˆ¶ID: {user_id}")
    print(f"   ç•¶å‰ä½ç½®: ({current_lat}, {current_lon})")
    print(f"   ç›®çš„åœ°: ({destination_lat}, {destination_lon})")
    print(f"   éœ€è¦æ¨è–¦æ•¸: {top_k}")
    
    # æ­¥é©Ÿ3: ç²å–æ¨è–¦
    print(f"\nğŸ¯ æ­¥é©Ÿ3: ç”Ÿæˆæ¨è–¦")
    recommendations = recommender.recommend_on_route(
        user_id=str(user_id),
        user_history=[],
        start_location=(current_lat, current_lon),
        end_location=(destination_lat, destination_lon),
        top_k=top_k
    )
    
    # æ­¥é©Ÿ4: é¡¯ç¤ºçµæœ
    print(f"\nğŸ“Š æ­¥é©Ÿ4: æ¨è–¦çµæœ")
    print_recommendations(recommendations)
    
    return recommendations


def example_2_with_llm_filter():
    """ç¯„ä¾‹2: ä½¿ç”¨LLMéæ¿¾çš„æ¨è–¦"""
    
    print("\n\n" + "=" * 60)
    print("ğŸ¤– ç¯„ä¾‹2: ä½¿ç”¨LLMéæ¿¾çš„æ¨è–¦ç³»çµ±")
    print("=" * 60)
    
    # æ­¥é©Ÿ1: åˆå§‹åŒ–æ¨è–¦å™¨ï¼ˆå•Ÿç”¨LLMï¼‰
    print("\nğŸ”§ æ­¥é©Ÿ1: åˆå§‹åŒ–æ¨è–¦å™¨ï¼ˆå•Ÿç”¨LLMéæ¿¾ï¼‰")
    
    osrm_client = OSRMClient(server_url="http://router.project-osrm.org")
    
    recommender = create_route_recommender(
        poi_data_path='datasets/meta-California.json.gz',
        model_checkpoint='models/travel_dlrm.pth',
        device='cuda' if torch.cuda.is_available() else 'cpu',
        enable_spatial_index=True,
        enable_async=True
    )
    recommender.osrm_client = osrm_client
    
    # å•Ÿç”¨LLMéæ¿¾
    recommender.enable_llm_filter = True
    if LLM_FILTER_AVAILABLE:
        try:
            recommender.llm_filter = SimpleLLMFilter()
            print(f"âœ… LLMéæ¿¾å™¨å·²å•Ÿç”¨")
        except Exception as e:
            print(f"âš ï¸ LLMå•Ÿç”¨å¤±æ•—: {e}")
            recommender.enable_llm_filter = False
    
    print("âœ… æ¨è–¦å™¨åˆå§‹åŒ–å®Œæˆ")
    print(f"   LLMç«¯é»: {recommender.llm_filter.base_url if recommender.llm_filter else 'æœªè¨­ç½®'}")
    
    # æ­¥é©Ÿ2: è¨­å®šæ¨è–¦åƒæ•¸
    print("\nğŸ“ æ­¥é©Ÿ2: è¨­å®šæ¨è–¦åƒæ•¸")
    user_id = 2
    current_lat = 37.7749
    current_lon = -122.4194
    destination_lat = 37.8199
    destination_lon = -122.4783
    top_k = 3
    
    print(f"   ç”¨æˆ¶ID: {user_id}")
    print(f"   éœ€è¦æ¨è–¦æ•¸: {top_k}")
    print(f"   ğŸ’¡ ç³»çµ±æœƒç”¨LLMéæ¿¾æ‰ä¸é©åˆæ—…å®¢çš„POI")
    
    # æ­¥é©Ÿ3: ç²å–æ¨è–¦ï¼ˆæœƒè‡ªå‹•ä½¿ç”¨LLMéæ¿¾ï¼‰
    print(f"\nğŸ¯ æ­¥é©Ÿ3: ç”Ÿæˆæ¨è–¦ï¼ˆå«LLMå¯©æ ¸ï¼‰")
    recommendations = recommender.recommend_on_route(
        user_id=str(user_id),
        user_history=[],
        start_location=(current_lat, current_lon),
        end_location=(destination_lat, destination_lon),
        top_k=top_k
    )
    
    # æ­¥é©Ÿ4: é¡¯ç¤ºçµæœ
    print(f"\nğŸ“Š æ­¥é©Ÿ4: LLMéæ¿¾å¾Œçš„æ¨è–¦çµæœ")
    print_recommendations(recommendations)
    
    return recommendations


def example_3_batch_recommendations():
    """ç¯„ä¾‹3: æ‰¹é‡æ¨è–¦ï¼ˆå¤šå€‹ç”¨æˆ¶ï¼‰"""
    
    print("\n\n" + "=" * 60)
    print("ğŸ‘¥ ç¯„ä¾‹3: æ‰¹é‡æ¨è–¦å¤šå€‹ç”¨æˆ¶")
    print("=" * 60)
    
    # åˆå§‹åŒ–æ¨è–¦å™¨
    print("\nğŸ”§ åˆå§‹åŒ–æ¨è–¦å™¨")
    
    osrm_client = OSRMClient(server_url="http://router.project-osrm.org")
    
    recommender = create_route_recommender(
        poi_data_path='datasets/meta-California.json.gz',
        model_checkpoint='models/travel_dlrm.pth',
        device='cuda' if torch.cuda.is_available() else 'cpu'
    )
    recommender.osrm_client = osrm_client
    recommender.enable_llm_filter = True
    if LLM_FILTER_AVAILABLE:
        recommender.llm_filter = SimpleLLMFilter()
    
    # å®šç¾©å¤šå€‹ç”¨æˆ¶çš„æ¨è–¦è«‹æ±‚
    user_requests = [
        {
            'user_id': 1,
            'current_lat': 37.7749,
            'current_lon': -122.4194,
            'destination_lat': 37.8199,
            'destination_lon': -122.4783,
            'name': 'ç”¨æˆ¶A - é‡‘é–€å¤§æ©‹éŠ'
        },
        {
            'user_id': 2,
            'current_lat': 37.7749,
            'current_lon': -122.4194,
            'destination_lat': 37.8086,
            'destination_lon': -122.4098,
            'name': 'ç”¨æˆ¶B - æ¼äººç¢¼é ­éŠ'
        },
        {
            'user_id': 3,
            'current_lat': 37.7749,
            'current_lon': -122.4194,
            'destination_lat': 37.7694,
            'destination_lon': -122.4862,
            'name': 'ç”¨æˆ¶C - é‡‘é–€å…¬åœ’éŠ'
        }
    ]
    
    # æ‰¹é‡è™•ç†
    print(f"\nğŸ¯ æ‰¹é‡è™•ç† {len(user_requests)} å€‹æ¨è–¦è«‹æ±‚")
    all_recommendations = {}
    
    for i, request in enumerate(user_requests, 1):
        print(f"\n{'â”€' * 50}")
        print(f"è™•ç†ç¬¬ {i}/{len(user_requests)} å€‹è«‹æ±‚: {request['name']}")
        
        recommendations = recommender.recommend_on_route(
            user_id=str(request['user_id']),
            user_history=[],
            start_location=(request['current_lat'], request['current_lon']),
            end_location=(request['destination_lat'], request['destination_lon']),
            top_k=3
        )
        
        all_recommendations[request['name']] = recommendations
        print(f"âœ… å®Œæˆï¼Œç²å¾— {len(recommendations)} å€‹æ¨è–¦")
    
    # é¡¯ç¤ºæ‰€æœ‰çµæœ
    print(f"\n\nğŸ“Š æ‰¹é‡æ¨è–¦ç¸½çµ")
    print("=" * 60)
    for name, recs in all_recommendations.items():
        print(f"\n{name}:")
        for i, rec in enumerate(recs, 1):
            poi = rec['poi']
            print(f"  {i}. {poi['name']} - {rec['score']:.3f}åˆ†")
    
    return all_recommendations


def example_4_custom_user_profile():
    """ç¯„ä¾‹4: ä½¿ç”¨è‡ªå®šç¾©ç”¨æˆ¶åå¥½"""
    
    print("\n\n" + "=" * 60)
    print("ğŸ‘¤ ç¯„ä¾‹4: è‡ªå®šç¾©ç”¨æˆ¶åå¥½æ¨è–¦")
    print("=" * 60)
    
    # åˆå§‹åŒ–
    osrm_client = OSRMClient(server_url="http://router.project-osrm.org")
    
    recommender = create_route_recommender(
        poi_data_path='datasets/meta-California.json.gz',
        model_checkpoint='models/travel_dlrm.pth',
        device='cuda' if torch.cuda.is_available() else 'cpu'
    )
    recommender.osrm_client = osrm_client
    recommender.enable_llm_filter = True
    if LLM_FILTER_AVAILABLE:
        recommender.llm_filter = SimpleLLMFilter()
    
    # å®šç¾©ç”¨æˆ¶åå¥½
    user_profile = {
        'preferred_categories': ['Restaurant', 'Cafe', 'Museum'],
        'min_rating': 4.0,
        'max_detour_minutes': 20,
        'prefer_popular': True
    }
    
    print("\nğŸ‘¤ ç”¨æˆ¶åå¥½è¨­å®š:")
    print(f"   åå¥½é¡åˆ¥: {', '.join(user_profile['preferred_categories'])}")
    print(f"   æœ€ä½è©•åˆ†: {user_profile['min_rating']}â­")
    print(f"   æœ€å¤§ç¹é“æ™‚é–“: {user_profile['max_detour_minutes']}åˆ†é˜")
    
    # ç²å–æ¨è–¦
    print("\nğŸ¯ æ ¹æ“šåå¥½ç”Ÿæˆæ¨è–¦")
    
    # æ³¨æ„ï¼šuser_profile éœ€è¦é€é user_history ä¾†å»ºç«‹
    # é€™è£¡æˆ‘å€‘ä½¿ç”¨ç©ºæ­·å²ï¼Œå¯¦éš›æ‡‰ç”¨ä¸­æ‡‰è©²æä¾›çœŸå¯¦æ­·å²è¨˜éŒ„
    recommendations = recommender.recommend_on_route(
        user_id='100',
        user_history=[],  # å¯ä»¥æ–°å¢æ­·å²POIè³‡è¨Š
        start_location=(37.7749, -122.4194),
        end_location=(37.8199, -122.4783),
        top_k=5
    )
    
    # é¡¯ç¤ºçµæœ
    print(f"\nğŸ“Š å€‹æ€§åŒ–æ¨è–¦çµæœ")
    print_recommendations(recommendations)
    
    return recommendations


def example_5_export_results():
    """ç¯„ä¾‹5: å°å‡ºæ¨è–¦çµæœåˆ°JSON"""
    
    print("\n\n" + "=" * 60)
    print("ğŸ’¾ ç¯„ä¾‹5: å°å‡ºæ¨è–¦çµæœ")
    print("=" * 60)
    
    # ç²å–æ¨è–¦
    osrm_client = OSRMClient(server_url="http://router.project-osrm.org")
    
    recommender = create_route_recommender(
        poi_data_path='datasets/meta-California.json.gz',
        model_checkpoint='models/travel_dlrm.pth',
        device='cuda' if torch.cuda.is_available() else 'cpu'
    )
    recommender.osrm_client = osrm_client
    recommender.enable_llm_filter = True
    if LLM_FILTER_AVAILABLE:
        recommender.llm_filter = SimpleLLMFilter()
    
    recommendations = recommender.recommend_on_route(
        user_id='1',
        user_history=[],
        start_location=(37.7749, -122.4194),
        end_location=(37.8199, -122.4783),
        top_k=5
    )
    
    # æº–å‚™å°å‡ºæ•¸æ“š
    export_data = {
        'user_id': 1,
        'timestamp': '2025-10-12T10:30:00',
        'route': {
            'start': {'lat': 37.7749, 'lon': -122.4194},
            'end': {'lat': 37.8199, 'lon': -122.4783}
        },
        'recommendations': []
    }
    
    # æ ¼å¼åŒ–æ¨è–¦çµæœ
    for i, rec in enumerate(recommendations, 1):
        poi = rec['poi']
        export_data['recommendations'].append({
            'rank': i,
            'poi_id': poi.get('poi_id', 'unknown'),
            'name': poi['name'],
            'category': poi.get('primary_category', 'Unknown'),
            'rating': poi.get('avg_rating', 0),
            'reviews': poi.get('num_reviews', 0),
            'location': {
                'latitude': poi['latitude'],
                'longitude': poi['longitude']
            },
            'score': rec['score'],
            'extra_time_minutes': rec['extra_time_minutes'],
            'llm_approved': rec.get('llm_approved', False),
            'reasons': rec.get('reasons', [])
        })
    
    # ä¿å­˜åˆ°æ–‡ä»¶
    output_file = 'recommendations_output.json'
    with open(output_file, 'w', encoding='utf-8') as f:
        json.dump(export_data, f, indent=2, ensure_ascii=False)
    
    print(f"âœ… æ¨è–¦çµæœå·²å°å‡ºåˆ°: {output_file}")
    print(f"   åŒ…å« {len(recommendations)} å€‹æ¨è–¦")
    
    # é¡¯ç¤ºé è¦½
    print(f"\nğŸ“„ æ–‡ä»¶é è¦½:")
    print(json.dumps(export_data, indent=2, ensure_ascii=False)[:500] + "...")
    
    return export_data


def print_recommendations(recommendations):
    """æ ¼å¼åŒ–é¡¯ç¤ºæ¨è–¦çµæœ"""
    if not recommendations:
        print("   âš ï¸ æ²’æœ‰æ¨è–¦çµæœ")
        return
    
    print(f"\nâœ… ç²å¾— {len(recommendations)} å€‹æ¨è–¦:")
    print("â”€" * 60)
    
    for i, rec in enumerate(recommendations, 1):
        poi = rec['poi']
        score = rec['score']
        extra_time = rec['extra_time_minutes']
        llm_approved = rec.get('llm_approved', False)
        
        print(f"\nğŸ¯ æ¨è–¦ #{i}")
        print(f"   åç¨±: {poi['name']}")
        print(f"   é¡åˆ¥: {poi.get('primary_category', 'æœªåˆ†é¡')}")
        print(f"   è©•åˆ†: {poi.get('avg_rating', 0):.1f}â­ ({poi.get('num_reviews', 0)} è©•è«–)")
        print(f"   ä½ç½®: ({poi['latitude']:.4f}, {poi['longitude']:.4f})")
        print(f"   AIè©•åˆ†: {score:.3f}")
        print(f"   é¡å¤–æ™‚é–“: {extra_time:.1f} åˆ†é˜")
        
        if llm_approved:
            print(f"   âœ… LLMå¯©æ ¸: é€šéï¼ˆé©åˆæ—…å®¢ï¼‰")
        
        # é¡¯ç¤ºæ¨è–¦ç†ç”±
        if 'reasons' in rec and rec['reasons']:
            print(f"   æ¨è–¦ç†ç”±:")
            for reason in rec['reasons'][:3]:  # æœ€å¤šé¡¯ç¤º3å€‹ç†ç”±
                print(f"      â€¢ {reason}")


def main():
    """ä¸»å‡½æ•¸ - åŸ·è¡Œæ‰€æœ‰ç¯„ä¾‹"""
    
    print("ğŸ® RouteX æ—…éŠæ¨è–¦ç³»çµ± - å®Œæ•´ä½¿ç”¨ç¯„ä¾‹")
    print("ğŸ”— LLMç«¯é»: 140.125.248.15:31008")
    print("ğŸ¤– æ¨¡å‹: nvidia/llama-3.3-nemotron-super-49b-v1")
    print()
    
    try:
        # ç¯„ä¾‹1: åŸºæœ¬ä½¿ç”¨
        example_1_basic_usage()
        
        # ç¯„ä¾‹2: LLMéæ¿¾
        print("\n\nâ¸ï¸  æŒ‰ Enter ç¹¼çºŒä¸‹ä¸€å€‹ç¯„ä¾‹...")
        input()
        example_2_with_llm_filter()
        
        # ç¯„ä¾‹3: æ‰¹é‡æ¨è–¦
        print("\n\nâ¸ï¸  æŒ‰ Enter ç¹¼çºŒä¸‹ä¸€å€‹ç¯„ä¾‹...")
        input()
        example_3_batch_recommendations()
        
        # ç¯„ä¾‹4: è‡ªå®šç¾©åå¥½
        print("\n\nâ¸ï¸  æŒ‰ Enter ç¹¼çºŒä¸‹ä¸€å€‹ç¯„ä¾‹...")
        input()
        example_4_custom_user_profile()
        
        # ç¯„ä¾‹5: å°å‡ºçµæœ
        print("\n\nâ¸ï¸  æŒ‰ Enter ç¹¼çºŒä¸‹ä¸€å€‹ç¯„ä¾‹...")
        input()
        example_5_export_results()
        
        print("\n\n" + "=" * 60)
        print("âœ… æ‰€æœ‰ç¯„ä¾‹åŸ·è¡Œå®Œæˆ!")
        print("=" * 60)
        
    except KeyboardInterrupt:
        print("\n\nâš ï¸ ç”¨æˆ¶ä¸­æ–·åŸ·è¡Œ")
    except Exception as e:
        print(f"\n\nâŒ åŸ·è¡ŒéŒ¯èª¤: {e}")
        import traceback
        traceback.print_exc()


if __name__ == "__main__":
    main()
